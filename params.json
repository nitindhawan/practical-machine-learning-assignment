{"name":"Practical Machine Learning - Course Project","tagline":"","body":"# Practical Machine Learning - Course Project\r\n========================================================\r\n\r\n## Methodology\r\n1. Divide the training set into 3 sets - 60:20:20 (train, test, test2).  \r\n2. Use training set for training different models - **rpart, random forest, knn** and **svm**.  \r\n3. Predict and create ConfusionMatrix on **test set** to measure performance of models and tuning parameters.\r\n4. For the best performing model in Step 3, use test2 set **exactly once** to compute Out Of Sample Error\r\n5. Predict using the best performing model in Step 3, classification for 20 test samples. Create the submission files\r\n\r\nTips: using foreach and doSNOW package to use 6 cores out of 8 cores on my windows computer\r\n\r\n\r\n```r\r\nlibrary(caret) \r\n```\r\n\r\n```\r\n## Loading required package: lattice\r\n## Loading required package: ggplot2\r\n```\r\n\r\n```r\r\nlibrary(foreach)\r\nlibrary(doSNOW)\r\n```\r\n\r\n```\r\n## Loading required package: iterators\r\n## Loading required package: snow\r\n```\r\n\r\n```r\r\nncores <- 6\r\nset.seed(1234)\r\n```\r\n\r\n\r\n```r\r\n# load data\r\nrawData <- read.csv(\"pml-training.csv\", na.strings=c(\"\", \"NA\", \"#DIV/0!\"))\r\n# discard NAs\r\nna.count <- apply(rawData, 2, function(x) {sum(is.na(x))}) \r\nvalidData <- rawData[, which(na.count == 0)]\r\n\r\n# remove useless predictors\r\nremoveColumns <- grep(\"timestamp|X|user_name|new_window|num_window\", names(validData))\r\nvalidData <- validData[ ,-removeColumns]\r\n\r\n# make training set 60\r\ntrainIndex     <- createDataPartition(y = validData$classe, p=0.60, list=FALSE)\r\ntrainData      <- validData[trainIndex, ]\r\nnontrainData   <- validData[-trainIndex, ]\r\n# divide test data into test and validation (20:20)\r\ntestIndex  <- createDataPartition(y = nontrainData$classe, p=0.50, list=FALSE)\r\ntestData   <- nontrainData[testIndex, ]\r\ntestData2  <- nontrainData[-testIndex, ]\r\n\r\nclasseColumnIndex <- grep(\"classe\", names(testData))\r\ndim(trainData); dim(testData); dim(testData2)\r\n```\r\n\r\n```\r\n## [1] 11776    53\r\n```\r\n\r\n```\r\n## [1] 3923   53\r\n```\r\n\r\n```\r\n## [1] 3923   53\r\n```\r\n# Rpart model\r\n\r\n\r\n```r\r\n# run rpart model\r\nsystem.time(\r\n        model_rpart <- train(classe ~ ., data = trainData, method=\"rpart\")\r\n        )\r\n```\r\n\r\n```\r\n## Loading required package: rpart\r\n```\r\n\r\n```\r\n##    user  system elapsed \r\n##   60.56    0.20   61.23\r\n```\r\n\r\n```r\r\nmodel_rpart\r\n```\r\n\r\n```\r\n## CART \r\n## \r\n## 11776 samples\r\n##    52 predictors\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Bootstrapped (25 reps) \r\n## \r\n## Summary of sample sizes: 11776, 11776, 11776, 11776, 11776, 11776, ... \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   cp    Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   0.04  0.5       0.4    0.03         0.04    \r\n##   0.06  0.4       0.2    0.06         0.1     \r\n##   0.1   0.3       0.07   0.04         0.06    \r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was cp = 0.04.\r\n```\r\n\r\n\r\n```r\r\npreds_rpart <- predict(model_rpart, testData[, -classeColumnIndex])\r\n```\r\n\r\n```\r\n## Loading required package: rpart\r\n```\r\n\r\n```r\r\nconfusionMatrix(preds_rpart, testData[, classeColumnIndex])\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1009  311  329  285  110\r\n##          B   15  253   29  109  104\r\n##          C   91  195  326  249  181\r\n##          D    0    0    0    0    0\r\n##          E    1    0    0    0  326\r\n## \r\n## Overall Statistics\r\n##                                         \r\n##                Accuracy : 0.488         \r\n##                  95% CI : (0.472, 0.504)\r\n##     No Information Rate : 0.284         \r\n##     P-Value [Acc > NIR] : <2e-16        \r\n##                                         \r\n##                   Kappa : 0.331         \r\n##  Mcnemar's Test P-Value : NA            \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity             0.904   0.3333   0.4766    0.000   0.4521\r\n## Specificity             0.631   0.9188   0.7789    1.000   0.9997\r\n## Pos Pred Value          0.494   0.4961   0.3129      NaN   0.9969\r\n## Neg Pred Value          0.943   0.8517   0.8757    0.836   0.8902\r\n## Prevalence              0.284   0.1935   0.1744    0.164   0.1838\r\n## Detection Rate          0.257   0.0645   0.0831    0.000   0.0831\r\n## Detection Prevalence    0.521   0.1300   0.2656    0.000   0.0834\r\n## Balanced Accuracy       0.768   0.6261   0.6278    0.500   0.7259\r\n```\r\n\r\n### Rpart model is not very accurate (only 50%). \r\n\r\n# Random Forest\r\n\r\n\r\n```r\r\n# power up cluster\r\ncl <- makeCluster(ncores)\r\nregisterDoSNOW(cl)\r\n\r\ncv_opts <- trainControl(method=\"cv\", number=10, allowParallel=TRUE)\r\n\r\n# run randomforest model\r\nsystem.time(\r\n        model_rf <- train(classe ~ ., data = trainData, \r\n                method=\"rf\", trControl = cv_opts)\r\n        )\r\n```\r\n\r\n```\r\n## Loading required package: randomForest\r\n## randomForest 4.6-7\r\n## Type rfNews() to see new features/changes/bug fixes.\r\n```\r\n\r\n```\r\n##    user  system elapsed \r\n##   48.08    0.30  459.26\r\n```\r\n\r\n```r\r\n# stop cluster\r\nstopCluster(cl)\r\n\r\nmodel_rf\r\n```\r\n\r\n```\r\n## Random Forest \r\n## \r\n## 11776 samples\r\n##    52 predictors\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (10 fold) \r\n## \r\n## Summary of sample sizes: 10599, 10600, 10598, 10598, 10599, 10598, ... \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   2     1         1      0.003        0.004   \r\n##   30    1         1      0.002        0.003   \r\n##   50    1         1      0.004        0.005   \r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 27.\r\n```\r\n\r\n\r\n```r\r\npreds_rf <- predict(model_rf, testData[, -classeColumnIndex])\r\n```\r\n\r\n```\r\n## Loading required package: randomForest\r\n## randomForest 4.6-7\r\n## Type rfNews() to see new features/changes/bug fixes.\r\n```\r\n\r\n```r\r\nconfusionMatrix(preds_rf, testData[, classeColumnIndex])\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1116    7    0    0    0\r\n##          B    0  750    5    0    4\r\n##          C    0    2  675    9    1\r\n##          D    0    0    4  632    3\r\n##          E    0    0    0    2  713\r\n## \r\n## Overall Statistics\r\n##                                         \r\n##                Accuracy : 0.991         \r\n##                  95% CI : (0.987, 0.993)\r\n##     No Information Rate : 0.284         \r\n##     P-Value [Acc > NIR] : <2e-16        \r\n##                                         \r\n##                   Kappa : 0.988         \r\n##  Mcnemar's Test P-Value : NA            \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity             1.000    0.988    0.987    0.983    0.989\r\n## Specificity             0.998    0.997    0.996    0.998    0.999\r\n## Pos Pred Value          0.994    0.988    0.983    0.989    0.997\r\n## Neg Pred Value          1.000    0.997    0.997    0.997    0.998\r\n## Prevalence              0.284    0.193    0.174    0.164    0.184\r\n## Detection Rate          0.284    0.191    0.172    0.161    0.182\r\n## Detection Prevalence    0.286    0.193    0.175    0.163    0.182\r\n## Balanced Accuracy       0.999    0.993    0.992    0.990    0.994\r\n```\r\n### Random Forest is highly accurate (99.1%)\r\n\r\n# KNN Model\r\n\r\n\r\n```r\r\n# power up cluster\r\ncl <- makeCluster(ncores)\r\nregisterDoSNOW(cl) \r\n\r\n# run knn model\r\nknn_opts <- data.frame(.k=c(seq(3, 11, 2)))\r\n\r\nsystem.time(\r\n        model_knn <- train(classe ~ ., data = trainData, \r\n                method=\"knn\",  trControl = cv_opts, tuneGrid = knn_opts)\r\n        )\r\n```\r\n\r\n```\r\n##    user  system elapsed \r\n##    0.78    0.10   54.41\r\n```\r\n\r\n```r\r\n# stop cluster\r\nstopCluster(cl)\r\n\r\nmodel_knn\r\n```\r\n\r\n```\r\n## k-Nearest Neighbors \r\n## \r\n## 11776 samples\r\n##    52 predictors\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (10 fold) \r\n## \r\n## Summary of sample sizes: 10598, 10598, 10599, 10600, 10599, 10599, ... \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   k   Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   3   0.9       0.9    0.008        0.01    \r\n##   5   0.9       0.9    0.01         0.02    \r\n##   7   0.9       0.8    0.01         0.02    \r\n##   9   0.8       0.8    0.01         0.02    \r\n##   10  0.8       0.8    0.01         0.01    \r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was k = 3.\r\n```\r\n\r\n\r\n```r\r\npreds_knn <- predict(model_knn, testData[, -classeColumnIndex])\r\nconfusionMatrix(preds_knn, testData[, classeColumnIndex])\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1086   26    5    8    7\r\n##          B    4  673   19    3   25\r\n##          C    6   25  630   32   17\r\n##          D   15   19   20  594   17\r\n##          E    5   16   10    6  655\r\n## \r\n## Overall Statistics\r\n##                                         \r\n##                Accuracy : 0.927         \r\n##                  95% CI : (0.919, 0.935)\r\n##     No Information Rate : 0.284         \r\n##     P-Value [Acc > NIR] : < 2e-16       \r\n##                                         \r\n##                   Kappa : 0.908         \r\n##  Mcnemar's Test P-Value : 5.05e-06      \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity             0.973    0.887    0.921    0.924    0.908\r\n## Specificity             0.984    0.984    0.975    0.978    0.988\r\n## Pos Pred Value          0.959    0.930    0.887    0.893    0.947\r\n## Neg Pred Value          0.989    0.973    0.983    0.985    0.980\r\n## Prevalence              0.284    0.193    0.174    0.164    0.184\r\n## Detection Rate          0.277    0.172    0.161    0.151    0.167\r\n## Detection Prevalence    0.289    0.185    0.181    0.170    0.176\r\n## Balanced Accuracy       0.978    0.935    0.948    0.951    0.948\r\n```\r\n### KNN is about 92.7% accurate, which is quite good and this was much faster to train than random forest.\r\n\r\n# SVM model\r\n\r\n\r\n```r\r\n# power up cluster\r\ncl <- makeCluster(ncores)\r\nregisterDoSNOW(cl)\r\n\r\n# run knn model\r\n\r\nsystem.time(\r\n        model_svm <- train(classe ~ ., data = trainData, \r\n                method=\"svmLinear\",  trControl = cv_opts, tuneLength = 5)\r\n        )\r\n```\r\n\r\n```\r\n## Loading required package: kernlab\r\n```\r\n\r\n```\r\n##    user  system elapsed \r\n##   15.57    0.33   75.76\r\n```\r\n\r\n```r\r\n# stop cluster\r\nstopCluster(cl)\r\n\r\nmodel_svm\r\n```\r\n\r\n```\r\n## Support Vector Machines with Linear Kernel \r\n## \r\n## 11776 samples\r\n##    52 predictors\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (10 fold) \r\n## \r\n## Summary of sample sizes: 10597, 10598, 10598, 10598, 10600, 10599, ... \r\n## \r\n## Resampling results\r\n## \r\n##   Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   0.8       0.7    0.02         0.02    \r\n## \r\n## Tuning parameter 'C' was held constant at a value of 1\r\n## \r\n```\r\n\r\n\r\n```r\r\npreds_svm <- predict(model_svm, testData[, -classeColumnIndex])\r\n```\r\n\r\n```\r\n## Loading required package: kernlab\r\n```\r\n\r\n```r\r\nconfusionMatrix(preds_svm, testData[, classeColumnIndex])\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1046  100   75   48   30\r\n##          B   14  548   64   32  101\r\n##          C   30   48  516   71   51\r\n##          D   24    8   19  454   38\r\n##          E    2   55   10   38  501\r\n## \r\n## Overall Statistics\r\n##                                         \r\n##                Accuracy : 0.781         \r\n##                  95% CI : (0.768, 0.794)\r\n##     No Information Rate : 0.284         \r\n##     P-Value [Acc > NIR] : <2e-16        \r\n##                                         \r\n##                   Kappa : 0.722         \r\n##  Mcnemar's Test P-Value : <2e-16        \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity             0.937    0.722    0.754    0.706    0.695\r\n## Specificity             0.910    0.933    0.938    0.973    0.967\r\n## Pos Pred Value          0.805    0.722    0.721    0.836    0.827\r\n## Neg Pred Value          0.973    0.933    0.948    0.944    0.934\r\n## Prevalence              0.284    0.193    0.174    0.164    0.184\r\n## Detection Rate          0.267    0.140    0.132    0.116    0.128\r\n## Detection Prevalence    0.331    0.193    0.183    0.138    0.154\r\n## Balanced Accuracy       0.924    0.828    0.846    0.839    0.831\r\n```\r\n### SVM was only 78.1% accurate. Which is not as good as others.\r\n\r\n# Results\r\n### We have the best prediction from Random Forest, so we select Random Forest as our final model.\r\n### First we calculate out of sample error on testData2 (which was havent used till now)\r\n\r\n```r\r\noos_rf <- predict(model_rf, testData2[, -classeColumnIndex])\r\nconfusionMatrix(oos_rf, testData2[, classeColumnIndex])\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1116   11    0    0    0\r\n##          B    0  744    9    1    0\r\n##          C    0    4  671   11    1\r\n##          D    0    0    4  631    1\r\n##          E    0    0    0    0  719\r\n## \r\n## Overall Statistics\r\n##                                         \r\n##                Accuracy : 0.989         \r\n##                  95% CI : (0.986, 0.992)\r\n##     No Information Rate : 0.284         \r\n##     P-Value [Acc > NIR] : <2e-16        \r\n##                                         \r\n##                   Kappa : 0.986         \r\n##  Mcnemar's Test P-Value : NA            \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity             1.000    0.980    0.981    0.981    0.997\r\n## Specificity             0.996    0.997    0.995    0.998    1.000\r\n## Pos Pred Value          0.990    0.987    0.977    0.992    1.000\r\n## Neg Pred Value          1.000    0.995    0.996    0.996    0.999\r\n## Prevalence              0.284    0.193    0.174    0.164    0.184\r\n## Detection Rate          0.284    0.190    0.171    0.161    0.183\r\n## Detection Prevalence    0.287    0.192    0.175    0.162    0.183\r\n## Balanced Accuracy       0.998    0.989    0.988    0.990    0.999\r\n```\r\n### Accuracy is 0.989.  \r\n### Out of Sample Error is 0.011.  \r\n### 95% CI is (0.008 to 0.014).  \r\n\r\n# Predicting outcome on given 20 test cases\r\n\r\n```r\r\n# Predict the outcomes in the given test file\r\nclassetestData <- read.csv(\"pml-testing.csv\", na.strings=c(\"\", \"NA\", \"#DIV/0!\"))\r\nremoveColumns <- grep(\"timestamp|X|user_name|new_window|num_window\", names(classetestData))\r\nclassetestData <- classetestData[ ,-removeColumns]\r\nanswers <- predict(model_rf, classetestData)\r\nanswers\r\n```\r\n\r\n```\r\n##  [1] B A B A A E D B A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n```\r\n\r\n```r\r\n# write output to files\r\n\r\npml_write_files <- function(answers){\r\n        x <- as.character(answers)\r\n        n = length(x)\r\n        for(i in 1:n){\r\n                filename = paste0(\"problem_id_\",i,\".txt\")\r\n                write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\r\n        }\r\n}\r\n\r\npml_write_files(answers)\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}